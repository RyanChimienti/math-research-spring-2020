\documentclass[12pt]{article}
\setlength\parindent{0pt}
\usepackage{mathtools}
\usepackage{amssymb,amsmath,amsthm,amsfonts}
\usepackage{thmtools}
\usepackage{cleveref}
\usepackage{changepage}
\usepackage{mathtools}
\usepackage[margin=0.75in]{geometry}
\setlength{\parindent}{1cm}

%Allows me to use begin{thm}, begin{lem}, etc.%
\newtheorem{thm}{Theorem}
\crefname{thm}{Theorem}{Theorems}
\newtheorem{prop}[thm]{Proposition}
\crefname{prop}{Proposition}{Propositions}
\newtheorem{corollary}[thm]{Corollary}
\crefname{corollary}{Corollary}{Corollaries}
\newtheorem{lem}[thm]{Lemma}
\crefname{lem}{Lemma}{Lemmas}
\declaretheoremstyle[
	headfont=\normalfont\itshape , 
	headindent=\parindent]{casestyle}
\declaretheorem[
	style=casestyle ,
	numberwithin=thm]{case}
\renewcommand{\thecase}{\arabic{case}} %Suppress thm # before case #
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{rem}[thm]{Remark}

%Helpful Shortcuts%
\newcommand{\N}{\mathbb N}
\newcommand{\Z}{\mathbb Z}
\newcommand{\Q}{\mathbb Q}
\newcommand{\R}{\mathbb R}
\newcommand{\C}{\mathbb C}
\DeclarePairedDelimiter\V{\langle}{\rangle} 
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%

%Allows me to make use of the \set* command, with a semicolon for the pipe.%
\usepackage{xparse}
%
\DeclarePairedDelimiterX{\set}[1]{\{}{\}}{\setargs{#1}}
\NewDocumentCommand{\setargs}{>{\SplitArgument{1}{;}}m}
{\setargsaux#1}
\NewDocumentCommand{\setargsaux}{mm}
{\IfNoValueTF{#2}{#1} {#1\,:\,\mathopen{}#2}}%{#1\:;\:#2}

\begin{document}

\section{The Magnetic Laplacian and its Spectrum}

\begin{defn}
A \textit{simple graph} is a set of vertices $V$ and a set of oriented edges $E \subseteq V \times V$, where for all $(v, w) \in E$, we have $v \neq w$ and $(w, v) \in E$.
\end{defn}

\begin{defn}
A \textit{magnetic graph} is a simple graph $(V, E)$ together with a \textit{signature} function $$\sigma : E \rightarrow \C_{\abs*{z}=1}$$ which has the property $\sigma(v, w) = \overline{\sigma(w,v)}$ for all $(v, w) \in E$. We may abbreviate $\sigma(v, w)$ as $\sigma_{vw}$.
\end{defn}

We may sometimes treat a simple graph as a magnetic graph, in which case all signatures are assumed to be 1. Unless we explicitly state the vertex set of a graph, it is assumed to be $\set*{1, \dots, n}$ for some $n$.

\begin{defn}
Suppose $G=(V, E)$ is a magnetic graph with vertices $\set*{1, \dots, n}$. The \textit{Laplacian} of $G$ is the $n$ x $n$ matrix $(l_{ij})$ given by 
$$
l_{ij} =
\begin{cases}
d_i &\mbox{ if } i=j \\
-\sigma_{ij} &\mbox{ otherwise}
\end{cases}
$$
for all $i, j \in \set*{1 \dots n}.$
\end{defn}

Note that this ``magnetic" definition for a Laplacian matches the familiar definition of a Laplacian when the graph is simple. The Laplacian always has a nice spectrum to analyze, as the following theorem shows.

\begin{thm}\label{spectral thm applied to Laplacian}
If $G$ is a magnetic graph with Laplacian $L$, then there is an orthonormal basis of $\C^n$ consisting of eigenvectors of $L$, and the eigenvalues of $L$ are real.
\end{thm}
\begin{proof}
$L$ is Hermitian because $L = L^*$. Therefore, the Complex Spectral Theorem gives this statement exactly.
\end{proof}

We also want to establish that the eigenvalues of the Laplacian are non-negative. We will follow Jiang's paper (Theorem 3.5 and the preceding discussion), but modified slightly for magnetic graphs.

\begin{defn}
Let $G=(E,V)$ be a magnetic graph on $n$ vertices with Laplacian $L$. For an edge $(e, v)$ of $G$, the \textit{contribution} of $(e, v)$ to $L$ is the $n$ x $n$ matrix $(l_{ij})$ given by
$$
l_{ij} =
\begin{cases}
1 &\mbox{ if } i=j \mbox{ and } i \in \set*{e, v} \\
-\sigma_{ij} &\mbox{ if } \set*{i,j} = \set*{e,v} \\
0 &\mbox{ otherwise}
\end{cases}.
$$ 
We denote this matrix $L_{(e, v)}$.
\end{defn}

As the name ``contribution" suggests, the Laplacian of a graph is the sum of the contributions of its edges (only counting one edge between each pair of vertices):

\begin{prop}
If $G$ is a magnetic graph with Laplacian $L$, then 
$$
L = \sum_{\substack{(i, j) \in E \\ i < j}} L_{(i, j)}.
$$
\end{prop}

For the next few propositions, remember that if $z \in \C$, then $z \geq 0$ means $z$ is real and nonnegative. Also, $\cdot$ is the complex dot product.

\begin{prop}\label{contributions to Laplacian are positive semi-definite}
Let $G=(E, V)$ be a magnetic graph on $n$ vertices with Laplacian $L$, and let $(i, j) \in E$. Then for any vector $v \in \C^n$, we have 
$$v \cdot L_{(i,j)} v \geq 0.$$
\end{prop}
\begin{proof}
Let $v = (v_1, \dots, v_n)$. By direct computation, the vector $L_{(i,j)}v$ consists of all 0s, except for $v_i-\sigma_{ij}v_j$ in the $i$th slot and $v_j-\sigma_{ji}v_i$ in the $j$th slot. Therefore,
\begin{align*}
v \cdot L_{(i,j)} v &= v_i \overline{v_i-\sigma_{ij}v_j} + v_j \overline{v_j-\sigma_{ji}v_i} \\
&= v_i \left(\overline{v_i} - \overline{\sigma_{ij}}\overline{v_j}\right) + v_j \left(\overline{v_j} - \overline{\sigma_{ji}}\overline{v_i}\right) \\
&= \abs*{v_i}^2 - v_i\overline{\sigma_{ij}}\overline{v_j} - v_j\overline{\sigma_{ji}}\overline{v_i} + \abs*{v_j}^2 \\
&= \abs*{v_i}^2 - \sigma_{ji}v_i\overline{v_j} - \overline{\sigma_{ji}v_i\overline{v_j}} + \abs*{v_j}^2 \\
&= \abs*{v_i}^2 - \left(\sigma_{ji}v_i\overline{v_j} + \overline{\sigma_{ji}v_i\overline{v_j}}\right) + \abs*{v_j}^2 \\
&= \abs*{v_i}^2 - 2 \mathrm{Re}\left(\sigma_{ji}v_i\overline{v_j}\right) + \abs*{v_j}^2 \\
&\geq \abs*{v_i}^2 - 2 \abs*{\mathrm{Re}\left(\sigma_{ji}v_i\overline{v_j}\right)} + \abs*{v_j}^2 \\
&\geq \abs*{v_i}^2 - 2 \abs*{\sigma_{ji}v_i\overline{v_j}} + \abs*{v_j}^2 \\
&= \abs*{v_i}^2 - 2 \abs*{\sigma_{ji}}\abs*{v_i}\abs*{\overline{v_j}} + \abs*{v_j}^2 \\
&= \abs*{v_i}^2 - 2 \abs*{\sigma_{ji}}\abs*{v_i}\abs*{\overline{v_j}} + \abs*{v_j}^2 \\
&= \abs*{v_i}^2 - 2 \abs*{v_i}\abs*{v_j} + \abs*{v_j}^2 \\
&= (\abs*{v_i} - \abs*{v_j})^2 \\
&\geq 0.
\end{align*}
\end{proof}

\begin{prop}\label{Laplacian is positive semi-definite}
Let $G=(E, V)$ be a magnetic graph on $n$ vertices with Laplacian $L$. Then for any vector $v \in \C^n$, we have 
$$v \cdot L v \geq 0.$$
\end{prop}
\begin{proof}
We have:
$$v \cdot Lv 
= v \cdot \left(\sum_{\substack{(i, j) \in E \\ i < j}} L_{(i, j)}\right)v
= v \cdot \sum_{\substack{(i, j) \in E \\ i < j}} L_{(i, j)} v = \sum_{\substack{(i, j) \in E \\ i < j}} \left(v \cdot L_{(i, j)} v\right),
$$
where the last equality holds because inner products are additive in the second slot. By \cref{contributions to Laplacian are positive semi-definite}, this is a sum of nonnegative real numbers, so $v \cdot Lv \geq 0$.
\end{proof}

\begin{thm}
If $G$ is a magnetic graph with Laplacian $L$, then the eigenvalues of $L$ are nonnegative.
\end{thm}
\begin{proof}
Let $\lambda$ be an eigenvalue of $L$, and let $v \in \C^n$ be a nonzero eigenvector corresponding to $\lambda$. Then,
\begin{align*}
\lambda (v \cdot v) &= v \cdot \overline\lambda v \\
&= v \cdot \lambda v &&\text{(since $\lambda$ is real by \cref{spectral thm applied to Laplacian})} \\
&= v \cdot L v \\
&\geq 0 &&\text{(by \cref{Laplacian is positive semi-definite})}. \\
\end{align*}
But $v$ is nonzero, so $v \cdot v \geq 0$ by the definition of inner product. Thus we may conclude that $\lambda \geq 0$.
\end{proof}

\section{Renumbering Vertices}

The Laplacian of a magnetic graph is only defined when the graph's vertices are numbered $1, \dots, n$, and changing the numbering changes the Laplacian. However, we will show in this section that changing the vertex numbering has no effect on the spectrum of the Laplacian. This will allow us to unambiguously refer to the ``spectrum of the Laplacian" of any magnetic graph, even if its vertices are not numbered or we don't know how they're numbered. With that goal in mind, we will first need a few facts about similar matrices.

\begin{prop}\label{similar matrices have same nullity}
Suppose $A$ and $B$ are similar $n \times n$ matrices over $\C$. Then $A$ and $B$ have the same nullity.
\end{prop}
\begin{proof}
Since $A$ and $B$ are similar, there exists an invertible matrix $P \in M_{n \times n}(\C)$ such that $$B = P^{-1} A P.$$ Let $k$ be the nullity of $A$. Then there exists a basis $x_1, \dots, x_k$ of $\ker A$, where each $x_i \in \C^n$. To show that $k$ is also the nullity of $B$, we will show that 
$$P^{-1}x_1, \dots, P^{-1}x_k$$
is a basis for $\ker B$. First note that those vectors are linearly independent, since $x_1, \dots, x_k$ are linearly independent, and an invertible linear map preserves linear independence. To see that $\text{span} (P^{-1}x_1, \dots, P^{-1}x_k) \subseteq \ker B$, observe that for any $i \in \set*{1, \dots, k}$, we have
\begin{align*}
B(P^{-1}x_i)
&= (P^{-1}AP)P^{-1}x_i \\
&= P^{-1} A x_i \\
&= P^{-1} (0) \\
&= 0,
\end{align*}
so $P^{-1}x_i \in \ker B$. It remains to show that $\ker B \subseteq \text{span} (P^{-1}x_1, \dots, P^{-1}x_k)$. To that end, let $v \in \ker B$. Then,
\begin{align*}
P^{-1}AP v = B v = 0 \\
&\rightarrow AP v = 0 \\
&\rightarrow Pv \in \ker A \\
&\rightarrow Pv = c_1 x_1 + \dots + c_k x_k &&\text{for some $c_1, \dots, c_k \in \C$} \\
&\rightarrow v = c_1 P^{-1} x_1 + \dots + c_k P^{-1} x_k &&\text{for some $c_1, \dots, c_k \in \C$} \\
&\rightarrow v \in \text{span} (P^{-1}x_1, \dots, P^{-1}x_k).
\end{align*} 
\end{proof}

\begin{prop}\label{similar matrices have same spectrum}
Suppose $A$ and $B$ are similar $n \times n$ matrices over $\C$. Then $A$ and $B$ have the same eigenvalues, counting multiplicity.
\end{prop}
\begin{proof}
Given $\lambda \in \C$ and $k \in \N$, we must show that $\lambda$ is an eigenvalue of $A$ with multiplicity $k$ if and only if $\lambda$ is an eigenvalue of $B$ with multiplicity $k$. The directions are analogous, so we will only show the forward direction. Suppose $\lambda$ is an eigenvalue of $A$ with multiplicity $k$. Since $A$ and $B$ are similar, there exists an invertible matrix $P \in M_{n \times n}(\C)$ such that 
$$B = P^{-1} A P.$$
Then, we have
\begin{align*}
\dim \ker (B - \lambda I) 
&= \dim \ker (P^{-1} A P - \lambda I) \\
&= \dim \ker (P^{-1} (A - \lambda I) P) \\
&= \dim \ker (A - \lambda I) &&\text{(by \cref{similar matrices have same nullity})} \\
&= k.
\end{align*}
Therefore, $\lambda$ is an eigenvalue of $B$ with multiplicity $k$.
\end{proof}

\begin{prop}
Let $\phi$ be a permutation of $\set*{1, \dots, n}$, and let $A, B \in M_{n \times n}(\C)$ be related by 
$$A_{ij} = B_{\phi(i)\phi(j)}$$
for all $i, j \in \set*{1, \dots, n}$. Then
$$A=P^{-1}BP$$
for some permutation matrix $P \in M_{n \times n}(\C)$.
\end{prop}
\begin{proof}
//TODO
\end{proof}

Finally we can prove the main theorem of this section:

\begin{thm}\label{renumbering vertices doesn't change Laplacian spectrum}
Let $G$ be a magnetic graph with vertices $\set*{1, \dots, n}$. Then renumbering the vertices of $G$ does not change the spectrum of its Laplacian.
\end{thm}
\begin{proof}
//TODO
\end{proof}

As an example of the importance of \cref{renumbering vertices doesn't change Laplacian spectrum}, the following theorem wouldn't make sense without it. //TODO explain further.

\begin{thm}\label{spectrum is sum of spectra of connected components}
Let $G$ be a magnetic graph with Laplacian $L$, and let $G_1, \dots G_k$ be the connected components of $G$, with Laplacians $L_1, \dots, L_k$. 
\end{thm}
\begin{proof}
//TODO
\end{proof}

\section{Balanced Magnetic Graphs}

\begin{defn}
A magnetic graph is called \textit{balanced} if the signatures along any closed walk multiply to 1.
\end{defn}

\begin{prop}\label{equivalent conditions for balancedness}
Let $G=(E, V, \sigma)$ be a magnetic graph. Then the following are equivalent.
\begin{enumerate}
\item G is balanced.
\item The signatures along any cycle multiply to 1 (in either direction).
\item For every pair of connected vertices $u, v \in V$, there exists $z \in \C_{\abs*{z}=1}$ such that along every walk from $u$ to $v$, the signatures multiply to $z$. 
\end{enumerate}
\end{prop}

Because the number $z$ in condition 3 is clearly unique for each pair of connected vertices, we can make the following definition.

\begin{defn}
Let $G=(E,V, \sigma)$ be a balanced magnetic graph, and let $u, v \in V$ be connected. Then the \textit{signature distance} from $u$ to $v$, written sigdist$(u, v)$, is the product of the signatures along every walk from $u$ to $v$.
\end{defn}

\section{Switching Equivalence}

\begin{defn}
If $G=(V, E, \sigma)$ is a magnetic graph, then a function $c: V \rightarrow \C_{\abs*{z}=1}$ is called a \textit{switching function} for $G$. We may write $c_v$ as shorthand for $c(v)$.
\end{defn}

\begin{defn}
Let $G = (V, E, \sigma)$ be a magnetic graph, and let $c$ be a switching function for $G$. Then $c$ \textit{applied to $G$} is the magnetic graph with the same edges and vertices, whose signature function $\tau$ is given by
$$\tau_{vw} = \overline{c_v}\sigma_{vw}c_w$$
for all $v \sim w$.
\end{defn}

\begin{defn}
A magnetic graph $G$ is \textit{switching equivalent} to a magnetic graph $H$ if there exists a switching function $c$ for $G$ such that $c$ applied to $G$ gives $H$.   
\end{defn}

\begin{prop}
Switching equivalence is an equivalence relation.
\end{prop}

\begin{prop}\label{switching equivalence of connected components}
Let $G^\sigma = (V, E, \sigma)$ and $G^\tau = (V, E, \tau)$ be two magnetic graphs with the same vertices and edges. Then $G^\sigma$ and $G^\tau$ are switching equivalent if and only if each connected component of $G^\sigma$ is switching equivalent to the corresponding connected component of $G^\tau$.
\end{prop}

\begin{proof}
$(\rightarrow)$ Suppose $G^\sigma$ and $G^\tau$ are switching equivalent. Then there is a switching function $c$ for $G^\sigma$ that, when applied to $G^\sigma$, gives $G^\tau$. Now let $C^\sigma=(U, D, \sigma|_{D})$ be an arbitrary connected component of $G^\sigma$. Then $C^\tau=(U, D, \tau|_{D})$ is the corresponding connected component of $G^\tau$. Choose $b$ to be the restriction of $c$ to $U$, and note that $b$ is a switching function for $C^\sigma$. It remains to show that $b$ applied to $C^\sigma$ gives $C^\tau$. Indeed, for any adjacent vertices $v, w \in U$, the signature of $(v, w)$ given by $b$ applied to $C^\sigma$ is
$$
\overline{b_v} (\sigma|_D)_{vw} b_w 
= \overline{c_v} \sigma_{vw} c_w
= \tau_{vw}
= (\tau|_{D})_{vw},
$$
which is the signature of $(v, w)$ in $C^\tau$.

$(\leftarrow)$ Suppose each connected component of $G^\sigma$ is switching equivalent to the corresponding connected component of $G^\tau$. Call the connected components $C_1, \dots, C_k.$ Then, for each $i \in \set*{1, \dots, k}$, let $b^i$ be the switching function that takes the $i$th connected component of $G^\sigma$ to the $i$th connected component of $G^\tau$. Define a switching function $c$ for $G^\sigma$ by $c_v = (b^i)_v$, where $i$ is such that $v$ belongs to $C_i$. It is easy to verify that $c$ applied to $G^\sigma$ gives $G^\tau$.
\end{proof}

We now work towards another characterization of switching equivalence. We want to show that two magnetic graphs with the same vertices and edges are switching equivalent if and only if the product of the signatures along any closed walk is the same for the two graphs. To make this easier, we will start with a lemma.

\begin{lem}\label{balanced implies switching equivalent to simple graph}
If $G=(V, E, \sigma)$ is a balanced magnetic graph, then $G$ is switching equivalent to the simple graph on $(V, E)$.
\end{lem}
\begin{proof}
Because of \cref{switching equivalence of connected components} and the fact that connected components of a balanced graph are also balanced, it suffices to prove the lemma in the case where $V$ is connected. So assume $V$ is connected. We must construct a switching function that takes every signature in $G$ to 1. To do this, fix a vertex $u_0 \in V$ and define the switching function $c: V \rightarrow \C_{|z|=1}$ by 
$$c_u = \overline{\text{sigdist} (u_0, u)}$$
for all $u \in V$. Then for every pair of adjacent vertices $v, w \in V$, we have
\begin{align*}
\overline{c_v} \sigma_{vw} c_w
&= \text{sigdist} (u_0, v) \sigma_{vw} \overline{\text{sigdist} (u_0, w)} \\
&= \text{sigdist} (u_0, w) \overline{\text{sigdist} (u_0, w)} \\
&= 1,
\end{align*}
as desired.
\end{proof}

\begin{thm}\label{closed walk characterization of switching equivalence}
Let $G^\sigma = (V, E, \sigma)$ and $G^\tau = (V, E, \tau)$ be two magnetic graphs with the same vertices and edges. Then $G^\sigma$ and $G^\tau$ are switching equivalent if and only if along every closed walk, the product of the signatures of $G^\sigma$ equals the product of the signatures of $G^\tau$.
\end{thm}
\begin{proof}
$(\rightarrow)$ Suppose $G^\sigma$ and $G^\tau$ are switching equivalent. Then there is a switching function $c: V \rightarrow \C_{\abs*z = 1}$ that takes $G^\sigma$ to $G^\tau$. Let $v_1, \dots, v_k$ be the vertices along a closed walk, so that $v_1 = v_k$. Then,
\begin{align*}
\sigma_{v_1 v_2} \sigma_{v_2 v_3} \dots \sigma_{v_{k-1} v_k}
&= \overline{c_{v_1}} \sigma_{v_1 v_2} \sigma_{v_2 v_3} \dots \sigma_{v_{k-1} v_k} c_{v_1} \\
&= \overline{c_{v_1}} \sigma_{v_1 v_2} \sigma_{v_2 v_3} \dots \sigma_{v_{k-1} v_k} c_{v_k} \\
&= (\overline{c_{v_1}} \sigma_{v_1 v_2} c_{v_2}) (\overline{c_{v_2}} \sigma_{v_2 v_3} c_{v_3}) \dots (\overline{c_{v_{k-1}}} \sigma_{v_{k-1} v_k} c_{v_k}) \\
&= \tau_{v_1 v_2} \tau_{v_2 v_3} \dots \tau_{v_{k-1} v_k}.
\end{align*} 
Therefore, along every closed walk, the product of the signatures of $G^\sigma$ equals the product of the signatures of $G^\tau$.

$(\leftarrow)$ Suppose that along every closed walk, the product of the signatures of $G^\sigma$ equals the product of the signatures of $G^\tau$. Define a new graph $G^s = (V, E, s)$, where the signatures $s$ are given by 
$$s_{vw} = \overline{\tau_{vw}} \sigma_{vw}$$ 
for all vertices $v \sim w$. It is easy to see that along any closed walk, the signatures of $G^s$ multiply to 1. Therefore, $G^s$ is balanced. By \cref{balanced implies switching equivalent to simple graph}, it follows that $G^s$ is switching equivalent to the simple graph on $(V, E)$, whose signatures are all 1. Call the switching function that takes $G^s$ to the simple graph $c$. Then for any vertices $v \sim w$, we have
\begin{align*}
\overline{c_v} s_{vw} c_w = 1
&\rightarrow \overline{c_v} \left(\overline{\tau_{vw}} \sigma_{vw}\right) c_w = 1 \\
&\rightarrow \overline{c_v} \sigma_{vw} c_w = \tau_{vw}.
\end{align*}
Therefore, applying the switching function $c$ to $G^\sigma$ gives $G^\tau$, so $G^\sigma$ and $G^\tau$ are switching equivalent.
\end{proof}

Many nice consequences flow from this characterization of switching equivalence. 

\begin{corollary}\label{balanced iff switching equivalent to simple graph}
A magnetic graph is balanced if and only if it is switching equivalent to the simple graph with the same vertices and edges.
\end{corollary}

\begin{corollary}
If a magnetic graph is switching equivalent to a balanced magnetic graph, then it is also balanced.  
\end{corollary}

\begin{corollary}
Any two balanced magnetic graphs with the same vertices and edges are switching equivalent. 
\end{corollary}

\begin{corollary}
Every acyclic magnetic graph is switching equivalent to the simple graph.
\end{corollary}

\begin{corollary}
Every magnetic cycle graph is switching equivalent to a graph which differs from the simple graph by at most one edge. 
\end{corollary}

The next theorem is why we care about switching equivalence in the context of spectral graph theory.

\begin{thm}\label{switching preserves spectrum}
Let $G^\sigma = (V, E, \sigma)$ and $G^\tau = (V, E, \tau)$ be magnetic graphs with the same vertices and edges. Then if $G^\sigma$ and $G^\tau$ are switching equivalent, it follows that their Laplacians have the same spectrum.
\end{thm}
\begin{proof}
Let $n$ be the number of vertices in $V$. Let $L^\sigma$ and $L^\tau$ be the Laplacians for $G^\sigma$ and $G^\tau$. Let $c$ be a switching function that takes $G^\sigma$ to $G^\tau$. Then, 
\begin{align*}
L^\tau &= \text{diag}(\overline{c_1}, \dots, \overline{c_n})\left(L^\sigma\right) \text{diag}(c_1, \dots, c_n) \\
&= \text{diag}(c_1, \dots, c_n)^{-1} \left(L^\sigma\right) \text{diag}(c_1, \dots, c_n).
\end{align*}
We see that $L^\sigma$ and $L^\tau$ are similar matrices. Therefore, by \cref{similar matrices have same spectrum}, they have the same spectrum.
\end{proof}

The converse of \cref{switching preserves spectrum} doesn't hold. For example, the 3-cycle graph with signatures 1, 1, and $i$ (going in order around the cycle) has the same spectrum as the 3-cycle graph with signatures 1, 1, and $-i$. However, the product along the cycles is different, so by \cref{closed walk characterization of switching equivalence}, the graphs cannot be switching equivalent. 

\section{The Eigenvalue 0 of the Laplacian}

If $G$ is a magnetic graph with vertices $\set*{1, \dots, n}$ and $x$ is a vector in $\C^n$, then it makes sense to imagine $x$ as consisting of values for the vertices of $G$. Specifically, the entry $x_i$ is like a value for the vertex $i$. With this interpretation, multiplying $x$ by the Laplacian of $G$ creates a new list of vertex values by taking linear combinations of the current vertex values. The weights of the combinations are determined by the structure of the Laplacian. In fact, the next proposition shows that a vertex's new value after the multiplication depends only on its current value and the values of its neighbors.   


\begin{prop}\label{Laplacian times vector}
Let $G$ be a magnetic graph on $n$ vertices with Laplacian $L$. Let $x \in \C^n$ with $x = (x_1, \dots, x_n)$. Then
$$(Lx)_i = d_ix_i - \sum_{j \sim i} \sigma_{ij} x_j$$
for each $i \in \set*{1, \dots, n}$.
\end{prop}
\begin{proof}
Let $l_{ij}$ denote the element of $L$ at row $i$ and column $j$. Let $i \in \set*{1, \dots, n}$ be given. Then,
\begin{align*}
(Lx)_i &= \sum_{j=1}^n l_{ij}x_j \\
&= l_{ii}x_i + \sum_{j \neq i} l_{ij}x_j \\
&= d_i x_i + \sum_{j \neq i} (-\sigma_{ij})x_j \\
&= d_i x_i - \sum_{j \neq i} \sigma_{ij}x_j.
\end{align*}
\end{proof}

We are particularly interested in when the ``vertex values" all go to 0 under multiplication by the Laplacian. It turns out that this happens exactly when each value is a signature-weighted average of the neighboring values, as the next lemma demonstrates.

\begin{lem}\label{entries of vector in Laplacian's null space are signature-weighted averages}
Let $G$ be a magnetic graph on $n$ vertices with Laplacian $L$. Suppose $x \in \C^n$ with $x = (x_1, \dots, x_n)$. Then $Lx = 0$ if and only if
$$x_i = \frac{1}{d_i} \sum_{j \sim i} \sigma_{ij}x_j$$
for each $i \in \set*{1, \dots n}$ with $d_i \neq 0$.
\end{lem}
\begin{proof}
This follows easily from \cref{Laplacian times vector}.
\end{proof}

We now show that this condition is equivalent to a much simpler one.

\begin{thm}\label{characterization of null space of Laplacian}
Let $G$ be a magnetic graph on $n$ vertices with Laplacian $L$. Suppose $x \in \C^n$ with $x = (x_1, \dots, x_n)$. Then $Lx = 0$ if and only if
$$x_i = \sigma_{ij}x_j$$
whenever $i \sim j$.
\end{thm}
\begin{proof}
$(\leftarrow)$ Suppose $x_i = \sigma_{ij}x_j$ whenever $i \sim j$. We will show that $Lx = 0$ using the condition from \cref{entries of vector in Laplacian's null space are signature-weighted averages}. Fix $i \in \set*{1, \dots, n}$ with $d_i \neq 0$. Then,
$$
x_i 
= \frac{1}{d_i} d_i x_i
= \frac{1}{d_i} \sum_{j \sim i} x_i
= \frac{1}{d_i} \sum_{j \sim i} \sigma_{ij}x_j.
$$ 

$(\rightarrow)$ Suppose $Lx = 0$. We first argue that whenever $a$ and $b$ are vertices in the same connected component of $G$, we have $\abs*{x_a} = \abs*{x_b}$. To see this, take an arbitrary connected component of $G$, and choose a vertex $m$ in that component which maximizes $\abs*{x_m}$. If $d_m = 0$, then $m$ is the only vertex in the component, so our conclusion holds trivially. On the other hand, if $d_m \neq 0$, then we can apply \cref{entries of vector in Laplacian's null space are signature-weighted averages} to get
\begin{align*}
\abs*{x_m} &= \abs*{\frac{1}{d_m} \sum_{l \sim m} \sigma_{ml} x_l} \\
&= \frac{1}{d_m} \abs*{\sum_{l \sim m} \sigma_{ml} x_l} \\
&\leq \frac{1}{d_m} \sum_{l \sim m} \abs*{\sigma_{ml} x_l} && \text{(by the Triangle Inequality)} \\
&= \frac{1}{d_m} \sum_{l \sim m} \abs*{x_l}.
\end{align*}
That is, $\abs*{x_m}$ is the mean of the values $\abs{x_l}$ where $l \sim m$. But our choice of $m$ ensures that $\abs*{x_m} \geq \abs*{x_l}$ for each $l \sim m$, so in fact $\abs*{x_m} = \abs*{x_l}$ for each $l \sim m$. It follows that any vertex $l$ which is adjacent to $m$ also maximizes the quantity $\abs*{x_l}$, so we can apply the same argument to each $l$, repeating the process until we conclude that $\abs*{x_a} = \abs*{x_b}$ for every pair of vertices $a, b$ in the connected component.

Now let $i$ and $j$ be vertices of $G$ with $i \sim j$. We want to prove that $x_i = \sigma_{ij}x_j$. From the previous paragraph, we already have that
$$\abs*{x_i} = \abs*{x_j} = \abs*{\sigma_{ij} x_j},$$
so it suffices to show $x_i$ differs from $\sigma_{ij} x_j$ by a positive real factor. Observe that 
\begin{align*}
\abs*{\sum_{l \sim i} \sigma_{il}x_l} &= \abs*{d_i x_i} && \text{(by \cref{entries of vector in Laplacian's null space are signature-weighted averages})} \\
&= d_i \abs*{x_i} \\
&= \sum_{l \sim i} \abs*{x_i} \\
&= \sum_{l \sim i} \abs*{x_l} && \text{(by the previous paragraph)} \\
&= \sum_{l \sim i} \abs*{\sigma_{il} x_l}.
\end{align*}
Therefore, assuming $\sigma_{ij} x_j \neq 0$ (the other case is trivial), we may conclude that 
$$\sum_{l \sim i} \sigma_{il}x_l = r (\sigma_{ij}x_j)$$
for some positive real $r$. Then,
\begin{align*}
x_i &= \frac{1}{d_i} \sum_{l \sim i} \sigma_{il}x_l && \text{(by \cref{entries of vector in Laplacian's null space are signature-weighted averages})} \\
&= \frac{1}{d_i} r (\sigma_{ij}x_j),
\end{align*}
so $x_i$ differs from $\sigma_{ij}x_j$ by a positive real factor, as desired.
\end{proof}

\begin{corollary}\label{null space of simple graph Laplacian}
Let $G$ be a simple graph on $n$ vertices with Laplacian $L$. Suppose $x \in \C^n$ with $x = (x_1, \dots, x_n)$. Then $Lx = 0$ if and only if $$x_i = x_j$$ whenever $i \sim j$.
\end{corollary}
\begin{proof}
This follows from \cref{characterization of null space of Laplacian} and the fact that every signature in a simple graph is 1.
\end{proof}

In a way, \cref{characterization of null space of Laplacian} completely answers the question of when 0 is an eigenvalue of the Laplacian. 0 is an eigenvalue exactly when there is a nonzero vector $x$ satisfying the condition in \cref{characterization of null space of Laplacian}. But that condition is phrased in terms of local properties of the graph. We want to find global properties that determine whether 0 is an eigenvalue, and if so, reveal its multiplicity. The final few results of the section achieve that.

\begin{prop}\label{multiplicity of 0 for connected balanced graph}
If $G$ is a connected and balanced magnetic graph, then 0 is an eigenvalue of its Laplacian with multiplicity 1. 
\end{prop}
\begin{proof}
Since $G$ is balanced, \cref{balanced iff switching equivalent to simple graph} gives that it is switching equivalent to the simple graph on the same edges and vertices. By \cref{switching preserves spectrum}, the spectrum of that simple graph is the same as the spectrum of $G$. So we only have to show that 0 is an eigenvalue with multiplicity 1 for the Laplacian of a connected, simple graph. Indeed, it is clear from \cref{null space of simple graph Laplacian} that the kernel of such a Laplacian is exactly the one-dimensional space of vectors whose entries are all the same.   
\end{proof}

\begin{prop}\label{multiplicity of 0 for connected unbalanced graph}
If $G$ is a connected and unbalanced magnetic graph, then 0 is not an eigenvalue of its Laplacian. 
\end{prop}
\begin{proof}
Let $n$ be the number of vertices in $G$, and let $x = (x_1, \dots, x_n) \in \ker L$. We will be done if we can show that $x$ must be $0$. Since $G$ is unbalanced, it has a closed walk along which the signatures multiply to some $c \neq 1$. Let $k$ be the starting and ending vertex of the walk. Repeated application of \cref{characterization of null space of Laplacian} along that walk gives that $x_k = c x_k$, so $x_k = 0$. Then applying \cref{characterization of null space of Laplacian} outward from $k$, we get $x_j = 0$ for every $j \in \set*{1, \dots, n}$. This means $x = 0$, as desired.
\end{proof}

\begin{thm}
Let $G$ be a magnetic graph with Laplacian $L$. Then the multiplicity of 0 as an eigenvalue of $L$ is equal to the number of balanced connected components of $G$.
\end{thm}
\begin{proof}
By \cref{spectrum is sum of spectra of connected components}, it suffices to sum the multiplicities of 0 as an eigenvalue for $G$'s connected components. By \cref{multiplicity of 0 for connected balanced graph}, the balanced components each contribute 1 multiplicity, and by \cref{multiplicity of 0 for connected unbalanced graph}, the unbalanced components each contribute 0 multiplicity. Therefore, the total multiplicity is the number of balanced components.
\end{proof}

\begin{corollary}
The Laplacian of a simple graph always has 0 as an eigenvalue, and its multiplicity is equal to the number of connected components in the graph.
\end{corollary}
\begin{proof}
A simple graph is balanced because all its signatures are 1. Thus all its connected components are balanced. Since the multiplicity of 0 is equal to the number of balanced components, in this case it is just equal to the total number of components.
\end{proof}

\end{document}
